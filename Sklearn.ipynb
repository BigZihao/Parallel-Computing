{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.014346</td>\n",
       "      <td>23.046831</td>\n",
       "      <td>7.705830</td>\n",
       "      <td>4.009119</td>\n",
       "      <td>5.791290</td>\n",
       "      <td>-5.942119</td>\n",
       "      <td>-3.926912</td>\n",
       "      <td>9.190385</td>\n",
       "      <td>12.641869</td>\n",
       "      <td>-25.103294</td>\n",
       "      <td>-1638.000533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.563790</td>\n",
       "      <td>-1.215983</td>\n",
       "      <td>0.813668</td>\n",
       "      <td>-9.796164</td>\n",
       "      <td>-1.200368</td>\n",
       "      <td>-14.770016</td>\n",
       "      <td>-11.070837</td>\n",
       "      <td>7.545220</td>\n",
       "      <td>-19.268883</td>\n",
       "      <td>10.934410</td>\n",
       "      <td>-613.651983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.111258</td>\n",
       "      <td>-9.015128</td>\n",
       "      <td>0.714845</td>\n",
       "      <td>16.777348</td>\n",
       "      <td>-5.576047</td>\n",
       "      <td>-0.437781</td>\n",
       "      <td>-0.572242</td>\n",
       "      <td>-6.591890</td>\n",
       "      <td>-0.561702</td>\n",
       "      <td>8.232941</td>\n",
       "      <td>590.328609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.166051</td>\n",
       "      <td>5.792263</td>\n",
       "      <td>10.105854</td>\n",
       "      <td>4.247606</td>\n",
       "      <td>10.716544</td>\n",
       "      <td>16.462863</td>\n",
       "      <td>-5.633654</td>\n",
       "      <td>-0.074374</td>\n",
       "      <td>15.116166</td>\n",
       "      <td>-30.846570</td>\n",
       "      <td>607.380150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-8.393955</td>\n",
       "      <td>5.564850</td>\n",
       "      <td>8.634882</td>\n",
       "      <td>13.440440</td>\n",
       "      <td>15.720117</td>\n",
       "      <td>-16.197428</td>\n",
       "      <td>3.570306</td>\n",
       "      <td>-6.356612</td>\n",
       "      <td>4.279428</td>\n",
       "      <td>-1.037903</td>\n",
       "      <td>-598.245553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1         X2         X3         X4         X5         X6  \\\n",
       "1 -13.014346  23.046831   7.705830   4.009119   5.791290  -5.942119   \n",
       "2  -5.563790  -1.215983   0.813668  -9.796164  -1.200368 -14.770016   \n",
       "3  -4.111258  -9.015128   0.714845  16.777348  -5.576047  -0.437781   \n",
       "4   5.166051   5.792263  10.105854   4.247606  10.716544  16.462863   \n",
       "5  -8.393955   5.564850   8.634882  13.440440  15.720117 -16.197428   \n",
       "\n",
       "          X7        X8         X9        X10            Y  \n",
       "1  -3.926912  9.190385  12.641869 -25.103294 -1638.000533  \n",
       "2 -11.070837  7.545220 -19.268883  10.934410  -613.651983  \n",
       "3  -0.572242 -6.591890  -0.561702   8.232941   590.328609  \n",
       "4  -5.633654 -0.074374  15.116166 -30.846570   607.380150  \n",
       "5   3.570306 -6.356612   4.279428  -1.037903  -598.245553  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('s3://analytic-partners-sparktest/test.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.980499505996704 seconds ---\n",
      "[  1.00887688   1.97717783   2.99673318   3.99057588   4.98238191\n",
      "   6.00236497   7.04115635   7.92452217   8.94738358  10.03835694]\n",
      "0.312271053282\n"
     ]
    }
   ],
   "source": [
    "X=data.drop('Y', 1)\n",
    "y = data.Y\n",
    "\n",
    "# follow the usual sklearn pattern: import, instantiate, fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "import time\n",
    "start_time = time.time()\n",
    "lm.fit(X, y)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# print intercept and coefficients\n",
    "print (lm.coef_)\n",
    "print (lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5.843400001525879 seconds ---\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.037\n",
      "Model:                            OLS   Adj. R-squared:                  0.037\n",
      "Method:                 Least Squares   F-statistic:                 3.838e+04\n",
      "Date:                Fri, 21 Apr 2017   Prob (F-statistic):               0.00\n",
      "Time:                        10:38:49   Log-Likelihood:            -8.3267e+07\n",
      "No. Observations:            10000000   AIC:                         1.665e+08\n",
      "Df Residuals:                 9999989   BIC:                         1.665e+08\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "X1             1.0089      0.032     31.912      0.000       0.947       1.071\n",
      "X2             1.9772      0.032     62.530      0.000       1.915       2.039\n",
      "X3             2.9967      0.032     94.755      0.000       2.935       3.059\n",
      "X4             3.9906      0.032    126.193      0.000       3.929       4.053\n",
      "X5             4.9824      0.032    157.552      0.000       4.920       5.044\n",
      "X6             6.0024      0.032    189.758      0.000       5.940       6.064\n",
      "X7             7.0412      0.032    222.704      0.000       6.979       7.103\n",
      "X8             7.9245      0.032    250.566      0.000       7.863       7.987\n",
      "X9             8.9474      0.032    282.778      0.000       8.885       9.009\n",
      "X10           10.0384      0.032    317.443      0.000       9.976      10.100\n",
      "Intercept      0.3123      0.332      0.941      0.346      -0.338       0.962\n",
      "==============================================================================\n",
      "Omnibus:                        1.584   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.453   Jarque-Bera (JB):                1.583\n",
      "Skew:                          -0.000   Prob(JB):                        0.453\n",
      "Kurtosis:                       3.002   Cond. No.                         11.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X2=X\n",
    "X2['Intercept']=1\n",
    "import time\n",
    "runtime=[]\n",
    "model = sm.OLS(y,X2)\n",
    "start_time = time.time()\n",
    "results = model.fit()\n",
    "tem=time.time() - start_time\n",
    "runtime.append(tem)\n",
    "print(\"--- %s seconds ---\" % (tem))\n",
    "print(results.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0020003318786621094 seconds ---\n",
      "0.001\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.039\n",
      "Model:                            OLS   Adj. R-squared:                  0.038\n",
      "Method:                 Least Squares   F-statistic:                     40.71\n",
      "Date:                Thu, 20 Apr 2017   Prob (F-statistic):           1.42e-79\n",
      "Time:                        16:28:00   Log-Likelihood:                -83222.\n",
      "No. Observations:               10000   AIC:                         1.665e+05\n",
      "Df Residuals:                    9989   BIC:                         1.665e+05\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "X1             0.5409      0.990      0.547      0.585      -1.399       2.481\n",
      "X2             2.2337      1.006      2.220      0.026       0.261       4.206\n",
      "X3             2.0987      0.990      2.119      0.034       0.158       4.040\n",
      "X4             4.4519      0.995      4.476      0.000       2.502       6.402\n",
      "X5             4.2051      0.995      4.227      0.000       2.255       6.155\n",
      "X6             5.6567      0.996      5.679      0.000       3.704       7.609\n",
      "X7             7.7601      0.987      7.860      0.000       5.825       9.695\n",
      "X8             6.9687      1.004      6.943      0.000       5.001       8.936\n",
      "X9             9.1955      1.002      9.178      0.000       7.232      11.159\n",
      "X10           11.3981      0.997     11.429      0.000       9.443      13.353\n",
      "Intercept     -2.8292     10.461     -0.270      0.787     -23.336      17.677\n",
      "==============================================================================\n",
      "Omnibus:                        0.906   Durbin-Watson:                   2.021\n",
      "Prob(Omnibus):                  0.636   Jarque-Bera (JB):                0.875\n",
      "Skew:                          -0.020   Prob(JB):                        0.646\n",
      "Kurtosis:                       3.022   Cond. No.                         11.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "--- 0.04000401496887207 seconds ---\n",
      "0.01\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.037\n",
      "Model:                            OLS   Adj. R-squared:                  0.037\n",
      "Method:                 Least Squares   F-statistic:                     381.5\n",
      "Date:                Thu, 20 Apr 2017   Prob (F-statistic):               0.00\n",
      "Time:                        16:28:00   Log-Likelihood:            -8.3280e+05\n",
      "No. Observations:              100000   AIC:                         1.666e+06\n",
      "Df Residuals:                   99989   BIC:                         1.666e+06\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "X1             1.0523      0.317      3.319      0.001       0.431       1.674\n",
      "X2             1.3148      0.317      4.151      0.000       0.694       1.936\n",
      "X3             3.2784      0.315     10.406      0.000       2.661       3.896\n",
      "X4             4.6717      0.317     14.759      0.000       4.051       5.292\n",
      "X5             5.3125      0.316     16.793      0.000       4.692       5.933\n",
      "X6             5.5567      0.317     17.530      0.000       4.935       6.178\n",
      "X7             7.1312      0.317     22.500      0.000       6.510       7.752\n",
      "X8             7.8217      0.318     24.583      0.000       7.198       8.445\n",
      "X9             8.8914      0.317     28.055      0.000       8.270       9.513\n",
      "X10            9.8243      0.317     31.002      0.000       9.203      10.445\n",
      "Intercept      3.2422      3.320      0.977      0.329      -3.265       9.749\n",
      "==============================================================================\n",
      "Omnibus:                        0.590   Durbin-Watson:                   2.010\n",
      "Prob(Omnibus):                  0.744   Jarque-Bera (JB):                0.580\n",
      "Skew:                          -0.005   Prob(JB):                        0.748\n",
      "Kurtosis:                       3.008   Cond. No.                         11.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "--- 0.562056303024292 seconds ---\n",
      "0.1\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.037\n",
      "Model:                            OLS   Adj. R-squared:                  0.037\n",
      "Method:                 Least Squares   F-statistic:                     3827.\n",
      "Date:                Thu, 20 Apr 2017   Prob (F-statistic):               0.00\n",
      "Time:                        16:28:01   Log-Likelihood:            -8.3272e+06\n",
      "No. Observations:             1000000   AIC:                         1.665e+07\n",
      "Df Residuals:                  999989   BIC:                         1.665e+07\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "X1             1.0235      0.100     10.225      0.000       0.827       1.220\n",
      "X2             1.9113      0.100     19.130      0.000       1.715       2.107\n",
      "X3             2.9529      0.100     29.529      0.000       2.757       3.149\n",
      "X4             4.0555      0.100     40.584      0.000       3.860       4.251\n",
      "X5             5.1063      0.100     51.015      0.000       4.910       5.302\n",
      "X6             5.9901      0.100     59.863      0.000       5.794       6.186\n",
      "X7             7.0588      0.100     70.534      0.000       6.863       7.255\n",
      "X8             7.9533      0.100     79.421      0.000       7.757       8.150\n",
      "X9             8.9329      0.100     89.281      0.000       8.737       9.129\n",
      "X10            9.9374      0.100     99.261      0.000       9.741      10.134\n",
      "Intercept      0.4640      1.050      0.442      0.659      -1.594       2.522\n",
      "==============================================================================\n",
      "Omnibus:                        4.030   Durbin-Watson:                   1.999\n",
      "Prob(Omnibus):                  0.133   Jarque-Bera (JB):                4.027\n",
      "Skew:                          -0.005   Prob(JB):                        0.134\n",
      "Kurtosis:                       3.002   Cond. No.                         11.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "--- 5.7005698680877686 seconds ---\n",
      "1\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.037\n",
      "Model:                            OLS   Adj. R-squared:                  0.037\n",
      "Method:                 Least Squares   F-statistic:                 3.838e+04\n",
      "Date:                Thu, 20 Apr 2017   Prob (F-statistic):               0.00\n",
      "Time:                        16:28:09   Log-Likelihood:            -8.3267e+07\n",
      "No. Observations:            10000000   AIC:                         1.665e+08\n",
      "Df Residuals:                 9999989   BIC:                         1.665e+08\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "X1             1.0089      0.032     31.912      0.000       0.947       1.071\n",
      "X2             1.9772      0.032     62.530      0.000       1.915       2.039\n",
      "X3             2.9967      0.032     94.755      0.000       2.935       3.059\n",
      "X4             3.9906      0.032    126.193      0.000       3.929       4.053\n",
      "X5             4.9824      0.032    157.552      0.000       4.920       5.044\n",
      "X6             6.0024      0.032    189.758      0.000       5.940       6.064\n",
      "X7             7.0412      0.032    222.704      0.000       6.979       7.103\n",
      "X8             7.9245      0.032    250.566      0.000       7.863       7.987\n",
      "X9             8.9474      0.032    282.778      0.000       8.885       9.009\n",
      "X10           10.0384      0.032    317.443      0.000       9.976      10.100\n",
      "Intercept      0.3123      0.332      0.941      0.346      -0.338       0.962\n",
      "==============================================================================\n",
      "Omnibus:                        1.584   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.453   Jarque-Bera (JB):                1.583\n",
      "Skew:                          -0.000   Prob(JB):                        0.453\n",
      "Kurtosis:                       3.002   Cond. No.                         11.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X2=X\n",
    "X2['Intercept']=1\n",
    "import time\n",
    "runtime=[]\n",
    "\n",
    "for i in [0.001,0.01,0.1,1]:\n",
    "    X3=X2[0:int(i*X.shape[0])]\n",
    "    y2=y[0:int(i*X.shape[0])]\n",
    "    model = sm.OLS(y2,X3)\n",
    "    start_time = time.time()\n",
    "    results = model.fit()\n",
    "    tem=time.time() - start_time\n",
    "    runtime.append(tem)\n",
    "    print(\"--- %s seconds ---\" % (tem))\n",
    "    print(i)\n",
    "    print(results.summary())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0020003318786621094,\n",
       " 0.04000401496887207,\n",
       " 0.562056303024292,\n",
       " 5.7005698680877686]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 261.5 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDRegressor(loss='squared_loss', penalty='none', alpha=0.001, l1_ratio=0, fit_intercept=True, n_iter=100, shuffle=True, verbose=0, epsilon=0.0001, random_state=None, learning_rate='invscaling', eta0=0.01, power_t=0.25, warm_start=False, average=False)\n",
    "start_time = time.time()\n",
    "clf.fit(X, y)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.45780883,   6.38755014,   2.51289849,  -4.13955781,\n",
       "         9.91256706,  12.86556171,   0.66877316,   4.18046777,\n",
       "         4.25872917,  10.74605276,   3.73444479])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03047157])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.22839999198913574 seconds ---\n",
      "0.001\n",
      "--- 2.937800168991089 seconds ---\n",
      "0.01\n",
      "--- 39.041800022125244 seconds ---\n",
      "0.1\n",
      "--- 498.6851999759674 seconds ---\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import time\n",
    "runtime=[]\n",
    "\n",
    "for i in [0.001,0.01,0.1,1]:\n",
    "    X2=X[0:int(i*X.shape[0])]\n",
    "    y2=y[0:int(i*X.shape[0])]\n",
    "    start_time = time.time()\n",
    "    clf.fit(X2, y2)\n",
    "    tem=time.time() - start_time\n",
    "    runtime.append(tem)\n",
    "    print(\"--- %s seconds ---\" % (tem))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode)\n",
      "  Starting server from C:\\Users\\zihao.zhang\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\ZIHAO~1.ZHA\\AppData\\Local\\Temp\\tmp9_80puns\n",
      "  JVM stdout: C:\\Users\\ZIHAO~1.ZHA\\AppData\\Local\\Temp\\tmp9_80puns\\h2o_zihao_zhang_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\ZIHAO~1.ZHA\\AppData\\Local\\Temp\\tmp9_80puns\\h2o_zihao_zhang_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>09 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.4.5</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 day </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_zihao_zhang_w5c45y</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.547 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.5.2 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------\n",
       "H2O cluster uptime:         09 secs\n",
       "H2O cluster version:        3.10.4.5\n",
       "H2O cluster version age:    1 day\n",
       "H2O cluster name:           H2O_from_python_zihao_zhang_w5c45y\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.547 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "Python version:             3.5.2 final\n",
       "--------------------------  ----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "trainFrame = h2o.import_file(path=\"C:/Users/zihao.zhang/Desktop/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2OGeneralizedLinearEstimator in module h2o.estimators.glm:\n",
      "\n",
      "class H2OGeneralizedLinearEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  Generalized Linear Modeling\n",
      " |  \n",
      " |  Fits a generalized linear model, specified by a response variable, a set of predictors, and a\n",
      " |  description of the error distribution.\n",
      " |  \n",
      " |  A subclass of :class:`ModelBase` is returned. The specific subclass depends on the machine learning task\n",
      " |  at hand (if it's binomial classification, then an H2OBinomialModel is returned, if it's regression then a\n",
      " |  H2ORegressionModel is returned). The default print-out of the models is shown, but further GLM-specific\n",
      " |  information can be queried out of the object. Upon completion of the GLM, the resulting object has\n",
      " |  coefficients, normalized coefficients, residual/null deviance, aic, and a host of model metrics including\n",
      " |  MSE, AUC (for logistic regression), degrees of freedom, and confusion matrices.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2OGeneralizedLinearEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.utils.backward_compatibility.BackwardsCompatibleBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Construct a new model instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  getGLMRegularizationPath(model)\n",
      " |      Extract full regularization path explored during lambda search from glm model.\n",
      " |      \n",
      " |      :param model: source lambda search model\n",
      " |  \n",
      " |  makeGLMModel(model, coefs, threshold=0.5)\n",
      " |      Create a custom GLM model using the given coefficients.\n",
      " |      \n",
      " |      Needs to be passed source model trained on the dataset to extract the dataset information from.\n",
      " |      \n",
      " |      :param model: source model, used for extracting dataset information\n",
      " |      :param coefs: dictionary containing model coefficients\n",
      " |      :param threshold: (optional, only for binomial) decision threshold used for classification\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  Lambda\n",
      " |      DEPRECATED. Use ``self.lambda_`` instead\n",
      " |  \n",
      " |  alpha\n",
      " |      distribution of regularization between L1 and L2. Default value of alpha is 0 when SOLVER = 'L-BFGS', 0.5\n",
      " |      otherwise\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  balance_classes\n",
      " |      Balance training data class counts via over/under-sampling (for imbalanced data).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  beta_constraints\n",
      " |      beta constraints\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  beta_epsilon\n",
      " |      converge if  beta changes less (using L-infinity norm) than beta esilon, ONLY applies to IRLSM solver\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.0001``).\n",
      " |  \n",
      " |  class_sampling_factors\n",
      " |      Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will\n",
      " |      be automatically computed to obtain class balance during training. Requires balance_classes.\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  compute_p_values\n",
      " |      request p-values computation, p-values work only with IRLSM solver and no regularization\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  early_stopping\n",
      " |      stop early when there is no more relative improvement on train or validation (if provided)\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  family\n",
      " |      Family. Use binomial for classification with logistic regression, others are for regression problems.\n",
      " |      \n",
      " |      One of: ``\"gaussian\"``, ``\"binomial\"``, ``\"quasibinomial\"``, ``\"multinomial\"``, ``\"poisson\"``, ``\"gamma\"``,\n",
      " |      ``\"tweedie\"``  (default: ``\"gaussian\"``).\n",
      " |  \n",
      " |  fold_assignment\n",
      " |      Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will stratify\n",
      " |      the folds based on the response variable, for classification problems.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"random\"``, ``\"modulo\"``, ``\"stratified\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  fold_column\n",
      " |      Column with cross-validation fold index assignment per observation.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  gradient_epsilon\n",
      " |      Converge if  objective changes less (using L-infinity norm) than this, ONLY applies to L-BFGS solver. Default\n",
      " |      indicates: If lambda_search is set to False and lambda is equal to zero, the default value of gradient_epsilon\n",
      " |      is equal to .000001, otherwise the default value is .0001. If lambda_search is set to True, the conditional\n",
      " |      values above are 1E-8 and 1E-6 respectively.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  ignore_const_cols\n",
      " |      Ignore constant columns.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  ignored_columns\n",
      " |      Names of columns to ignore for training.\n",
      " |      \n",
      " |      Type: ``List[str]``.\n",
      " |  \n",
      " |  interactions\n",
      " |      A list of predictor column indices to interact. All pairwise combinations will be computed for the list.\n",
      " |      \n",
      " |      Type: ``List[str]``.\n",
      " |  \n",
      " |  intercept\n",
      " |      include constant term in the model\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  keep_cross_validation_fold_assignment\n",
      " |      Whether to keep the cross-validation fold assignment.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  keep_cross_validation_predictions\n",
      " |      Whether to keep the predictions of the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  lambda_\n",
      " |      regularization strength\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  lambda_min_ratio\n",
      " |      Min lambda used in lambda search, specified as a ratio of lambda_max. Default indicates: if the number of\n",
      " |      observations is greater than the number of variables then lambda_min_ratio is set to 0.0001; if the number of\n",
      " |      observations is less than the number of variables then lambda_min_ratio is set to 0.01.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  lambda_search\n",
      " |      use lambda search starting at lambda max, given lambda is then interpreted as lambda min\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  link\n",
      " |      One of: ``\"family_default\"``, ``\"identity\"``, ``\"logit\"``, ``\"log\"``, ``\"inverse\"``, ``\"tweedie\"``  (default:\n",
      " |      ``\"family_default\"``).\n",
      " |  \n",
      " |  max_active_predictors\n",
      " |      Maximum number of active predictors during computation. Use as a stopping criterion to prevent expensive model\n",
      " |      building with many predictors. Default indicates: If the IRLSM solver is used, the value of\n",
      " |      max_active_predictors is set to 7000 otherwise it is set to 100000000.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  max_after_balance_size\n",
      " |      Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires\n",
      " |      balance_classes.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``5``).\n",
      " |  \n",
      " |  max_confusion_matrix_size\n",
      " |      [Deprecated] Maximum size (# classes) for confusion matrices to be printed in the Logs\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  max_hit_ratio_k\n",
      " |      Max. number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  max_iterations\n",
      " |      Maximum number of iterations\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  max_runtime_secs\n",
      " |      Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  missing_values_handling\n",
      " |      Handling of missing values. Either MeanImputation or Skip.\n",
      " |      \n",
      " |      One of: ``\"mean_imputation\"``, ``\"skip\"``  (default: ``\"mean_imputation\"``).\n",
      " |  \n",
      " |  nfolds\n",
      " |      Number of folds for N-fold cross-validation (0 to disable or >= 2).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  nlambdas\n",
      " |      Number of lambdas to be used in a search. Default indicates: If alpha is zero, with lambda search set to True,\n",
      " |      the value of nlamdas is set to 30 (fewer lambdas are needed for ridge regression) otherwise it is set to 100.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  non_negative\n",
      " |      Restrict coefficients (not intercept) to be non-negative\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  objective_epsilon\n",
      " |      Converge if  objective value changes less than this. Default indicates: If lambda_search is set to True the\n",
      " |      value of objective_epsilon is set to .0001. If the lambda_search is set to False and lambda is equal to zero,\n",
      " |      the value of objective_epsilon is set to .000001, for any other value of lambda the default value of\n",
      " |      objective_epsilon is set to .0001.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  offset_column\n",
      " |      Offset column. This will be added to the combination of columns before applying the link function.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  prior\n",
      " |      prior probability for y==1. To be used only for logistic regression iff the data has been sampled and the mean\n",
      " |      of response does not reflect reality.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``-1``).\n",
      " |  \n",
      " |  remove_collinear_columns\n",
      " |      in case of linearly dependent columns remove some of the dependent columns\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  response_column\n",
      " |      Response variable column.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  score_each_iteration\n",
      " |      Whether to score during each iteration of model training.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  seed\n",
      " |      Seed for pseudo random number generator (if applicable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  solver\n",
      " |      AUTO will set the solver based on given data and the other parameters. IRLSM is fast on on problems with small\n",
      " |      number of predictors and for lambda-search with L1 penalty, L_BFGS scales better for datasets with many columns.\n",
      " |      Coordinate descent is experimental (beta).\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"irlsm\"``, ``\"l_bfgs\"``, ``\"coordinate_descent_naive\"``, ``\"coordinate_descent\"``\n",
      " |      (default: ``\"auto\"``).\n",
      " |  \n",
      " |  standardize\n",
      " |      Standardize numeric columns to have zero mean and unit variance\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  training_frame\n",
      " |      Id of the training data frame (Not required, to allow initial validation of model parameters).\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  tweedie_link_power\n",
      " |      Tweedie link power\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  tweedie_variance_power\n",
      " |      Tweedie variance power\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  validation_frame\n",
      " |      Id of the validation data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  weights_column\n",
      " |      Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the\n",
      " |      dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative\n",
      " |      weights are not allowed.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  algo = 'glm'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  fit(self, x, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      :param H2OFrame x: An H2OFrame consisting of the predictor variables.\n",
      " |      :param H2OFrame y: An H2OFrame consisting of the response variable.\n",
      " |      :param params: Extra arguments.\n",
      " |      :returns: The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Obtain parameters for this estimator.\n",
      " |      \n",
      " |      Used primarily for sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      :param deep: If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      :returns: A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |      Wait until job's completion.\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      :param parms: A dictionary of parameters that will be set on this model.\n",
      " |      :returns: self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the model asynchronously (to block for results call :meth:`join`).\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, model_id=None)\n",
      " |      Train the H2O model.\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |      :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC (Akaike Information Criterium).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AIC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC (Area Under Curve).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AUC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AUC.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector.\n",
      " |      \n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding.\n",
      " |  \n",
      " |  coef(self)\n",
      " |      Return the coefficients which can be applied to the non-standardized data.\n",
      " |      \n",
      " |      Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      Return coefficients fitted on the standardized data (requires standardize = True, which is on by default).\n",
      " |      \n",
      " |      These coefficients can be used to evaluate variable importance.\n",
      " |  \n",
      " |  cross_validation_fold_assignment(self)\n",
      " |      Obtain the cross-validation fold assignment for all rows in the training data.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_holdout_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on the training data.\n",
      " |      \n",
      " |      This is equivalent to summing up all H2OFrames returned by cross_validation_predictions.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_metrics_summary(self)\n",
      " |      Retrieve Cross-Validation Metrics Summary.\n",
      " |      \n",
      " |      :returns: The cross-validation metrics summary as an H2OTwoDimTable\n",
      " |  \n",
      " |  cross_validation_models(self)\n",
      " |      Obtain a list of cross-validation models.\n",
      " |      \n",
      " |      :returns: list of H2OModel objects.\n",
      " |  \n",
      " |  cross_validation_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on their holdout data.\n",
      " |      \n",
      " |      Note that the predictions are expanded to the full number of rows of the training data, with 0 fill-in.\n",
      " |      \n",
      " |      :returns: list of H2OFrame objects.\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details.\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  download_mojo(self, path='.', get_genmodel_jar=False)\n",
      " |      Download the model in MOJO format.\n",
      " |      \n",
      " |      :param path: the path where MOJO file should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :returns: name of the MOJO file written.\n",
      " |  \n",
      " |  download_pojo(self, path='', get_genmodel_jar=False)\n",
      " |      Download the POJO for this model to the directory specified by path.\n",
      " |      \n",
      " |      If path is an empty string, then dump the output to screen.\n",
      " |      \n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :returns: name of the POJO file written.\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      \n",
      " |      :returns: A model or list of models.\n",
      " |  \n",
      " |  gini(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini coefficient.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\"\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      Return True if the model was cross-validated.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the log loss value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the log loss value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the log loss value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The log loss for this regression model.\n",
      " |  \n",
      " |  mae(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Absolute Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MAE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MAE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MAE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MAE for this regression model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  metalearner(self)\n",
      " |      Print the metalearner for the model, if any.  Currently only used by H2OStackedEnsembleEstimator.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False, xval=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data set for which model metrics shall be computed against. All three of train,\n",
      " |          valid and xval arguments are ignored if test_data is not None.\n",
      " |      :param bool train: Report the training metrics for the model.\n",
      " |      :param bool valid: Report the validation metrics for the model.\n",
      " |      :param bool xval: Report the cross-validation metrics for the model. If train and valid are True, then it\n",
      " |          defaults to True.\n",
      " |      \n",
      " |      :returns: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors.\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors.\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null dof for the training set. If both train and valid are False, then train is\n",
      " |          selected by default.\n",
      " |      :param bool valid: Get the null dof for the validation set. If both train and valid are True, then train is\n",
      " |          selected by default.\n",
      " |      \n",
      " |      :returns: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null deviance for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the null deviance for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  partial_plot(self, data, cols, destination_key=None, nbins=20, plot=True, plot_stddev=True, figsize=(7, 10), server=False)\n",
      " |      Create partial dependence plot which gives a graphical depiction of the marginal effect of a variable on the\n",
      " |      response. The effect of a variable is measured in change in the mean response.\n",
      " |      \n",
      " |      :param H2OFrame data: An H2OFrame object used for scoring and constructing the plot.\n",
      " |      :param cols: Feature(s) for which partial dependence will be calculated.\n",
      " |      :param destination_key: An key reference to the created partial dependence tables in H2O.\n",
      " |      :param nbins: Number of bins used. For categorical columns make sure the number of bins exceed the level count.\n",
      " |      :param plot: A boolean specifying whether to plot partial dependence table.\n",
      " |      :param plot_stddev: A boolean specifying whether to add std err to partial dependence plot.\n",
      " |      :param figsize: Dimension/size of the returning plots, adjust to fit your output cells.\n",
      " |      :param server: ?\n",
      " |      :returns: Plot and list of calculated mean response tables for each feature requested.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients).\n",
      " |  \n",
      " |  predict(self, test_data)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  predict_leaf_node_assignment(self, test_data)\n",
      " |      Predict on a dataset and return the leaf node assignment (only for tree-based models).\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R squared for this regression model.\n",
      " |      \n",
      " |      Will return R^2 for GLM Models and will return NaN otherwise.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var, where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The R squared for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=None)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual deviance for the training set. If both train and valid are False, then\n",
      " |          train is selected by default.\n",
      " |      :param bool valid: Get the residual deviance for the validation set. If both train and valid are True, then\n",
      " |          train is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response.\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response.\n",
      " |  \n",
      " |  rmse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSE for this regression model.\n",
      " |  \n",
      " |  rmsle(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Squared Logarithmic Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSLE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSLE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSLE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSLE for this regression model.\n",
      " |  \n",
      " |  rotation(self)\n",
      " |      Obtain the rotations (eigenvectors) for a PCA model\n",
      " |      \n",
      " |      :return: H2OFrame\n",
      " |  \n",
      " |  save_model_details(self, path='', force=False)\n",
      " |      Save Model Details of an H2O Model in JSON Format to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model details at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model details\n",
      " |  \n",
      " |  save_mojo(self, path='', force=False)\n",
      " |      Save an H2O Model as MOJO (Model Object, Optimized) to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      DEPRECATED. Use :meth:`scoring_history` instead.\n",
      " |  \n",
      " |  scoring_history(self)\n",
      " |      Retrieve Model Score History.\n",
      " |      \n",
      " |      :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type.\n",
      " |  \n",
      " |  std_coef_plot(self, num_of_features=None, server=False)\n",
      " |      Plot a GLM model\"s standardized coefficient magnitudes.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |  \n",
      " |  varimp(self, use_pandas=False)\n",
      " |      Pretty print the variable importances, or return them in a list.\n",
      " |      \n",
      " |      :param use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n",
      " |      \n",
      " |      :returns: A list or Pandas DataFrame.\n",
      " |  \n",
      " |  varimp_plot(self, num_of_features=None, server=False)\n",
      " |      Plot the variable importance for a trained model.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix.\n",
      " |      \n",
      " |      :param: matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      Return model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  actual_params\n",
      " |      Dictionary of actual parameters of the model.\n",
      " |  \n",
      " |  default_params\n",
      " |      Dictionary of the default parameters of the model.\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Dictionary of the full specification of all parameters.\n",
      " |  \n",
      " |  model_id\n",
      " |      Model identifier.\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :returns: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  type\n",
      " |      The type of model built: ``\"classifier\"`` or ``\"regressor\"`` or ``\"unsupervised\"``\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :returns: A list of models.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __getattr__(self, item)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(H2OGeneralizedLinearEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glm_multi_v1 = H2OGeneralizedLinearEstimator(\n",
    "                    model_id='glm_v1',            #allows us to easily locate this model in Flow\n",
    "                    family='gaussian',\n",
    "                    solver='L_BFGS',\n",
    "standardize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFrame.col_names[1:11] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "covtype_X = trainFrame.col_names[1:11]     #last column is Cover_Type, our desired response variable \n",
    "covtype_y = trainFrame.col_names[11]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "glm_multi_v1.train(covtype_X, covtype_y, training_frame=trainFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intercept': 0.858502401872342,\n",
       " 'X1': 0.9967921966564366,\n",
       " 'X10': 9.935978479674798,\n",
       " 'X2': 1.9550603816737633,\n",
       " 'X3': 2.9687107225956226,\n",
       " 'X4': 3.9510736964627515,\n",
       " 'X5': 4.937555475023985,\n",
       " 'X6': 5.941839898577547,\n",
       " 'X7': 6.974217188747334,\n",
       " 'X8': 7.8431535087190465,\n",
       " 'X9': 8.859288277676349}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_multi_v1.coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "--- 19.384061813354492 seconds ---\n",
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "--- 20.35202407836914 seconds ---\n",
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "--- 20.77623701095581 seconds ---\n",
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "--- 20.393999814987183 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "runtime2=[]\n",
    "\n",
    "for i in [0.001,0.01,0.1,1]:\n",
    "    train=trainFrame[0:int(i*trainFrame.shape[0])]\n",
    "    start_time = time.time()\n",
    "    glm_multi_v1.train(covtype_X, covtype_y, training_frame=train)\n",
    "    tem=time.time() - start_time\n",
    "    runtime2.append(tem)\n",
    "    print(\"--- %s seconds ---\" % (tem))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
